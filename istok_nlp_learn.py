import spacy
from typing import Dict, Any, List, Optional
from datetime import datetime
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
from pathlib import Path

class IIoTAnalyzer:
    def __init__(self, model_path: Optional[str] = None):
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ NLP Ð¼Ð¾Ð´ÐµÐ»Ð¸
        if model_path and Path(model_path).exists():
            self.nlp = spacy.load(model_path)
            print("âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð°Ñ NER Ð¼Ð¾Ð´ÐµÐ»ÑŒ")
        else:
            self.nlp = spacy.blank("ru")
            print("ðŸ†• Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° Ð½Ð¾Ð²Ð°Ñ NER Ð¼Ð¾Ð´ÐµÐ»ÑŒ")

        # Ð¡Ð»Ð¾Ð²Ð°Ñ€Ð¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½ÐµÐ¸ÑÐ¿Ñ€Ð°Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹
        self.equipment_types = {
            "ÑÑ‚Ð°Ð½Ð¾Ðº": "Ð¡Ñ‚Ð°Ð½Ð¾Ðº", "Ð¿Ñ€ÐµÑÑ": "ÐŸÑ€ÐµÑÑ", "Ñ€Ð¾Ð±Ð¾Ñ‚": "Ð Ð¾Ð±Ð¾Ñ‚",
            "ÐºÐ¾Ð½Ð²ÐµÐ¹ÐµÑ€": "ÐšÐ¾Ð½Ð²ÐµÐ¹ÐµÑ€", "ÐºÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¾Ñ€": "ÐšÐ¾Ð¼Ð¿Ñ€ÐµÑÑÐ¾Ñ€"
        }

        self.components = {
            "ÑˆÐ¿Ð¸Ð½Ð´ÐµÐ»ÑŒ": "Ð¨Ð¿Ð¸Ð½Ð´ÐµÐ»ÑŒ", "Ð¿Ð¾Ð´ÑˆÐ¸Ð¿Ð½Ð¸Ðº": "ÐŸÐ¾Ð´ÑˆÐ¸Ð¿Ð½Ð¸Ðº",
            "Ð³Ð¸Ð´Ñ€Ð°Ð²Ð»Ð¸ÐºÐ°": "Ð“Ð¸Ð´Ñ€Ð°Ð²Ð»Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°", "ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð´Ð²Ð¸Ð³Ð°Ñ‚ÐµÐ»ÑŒ": "Ð­Ð»ÐµÐºÑ‚Ñ€Ð¾Ð´Ð²Ð¸Ð³Ð°Ñ‚ÐµÐ»ÑŒ",
            "Ñ€ÐµÐ¼ÐµÐ½ÑŒ": "Ð ÐµÐ¼ÐµÐ½ÑŒ", "Ð¿Ð°Ð½ÐµÐ»ÑŒ": "ÐŸÐ°Ð½ÐµÐ»ÑŒ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ"
        }

        self.symptoms = {
            "ÑˆÑƒÐ¼": "ÐÐµÑ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð½Ñ‹Ð¹ ÑˆÑƒÐ¼", "Ð²Ð¸Ð±Ñ€Ð°Ñ†Ð¸Ñ": "Ð’Ð¸Ð±Ñ€Ð°Ñ†Ð¸Ñ",
            "Ð¿ÐµÑ€ÐµÐ³Ñ€ÐµÐ²": "ÐŸÐµÑ€ÐµÐ³Ñ€ÐµÐ²", "Ñ‚ÐµÑ‡ÑŒ": "Ð¢ÐµÑ‡ÑŒ Ð¶Ð¸Ð´ÐºÐ¾ÑÑ‚Ð¸",
            "Ð¾ÑˆÐ¸Ð±ÐºÐ°": "ÐšÐ¾Ð´ Ð¾ÑˆÐ¸Ð±ÐºÐ¸", "Ð·Ð°ÐºÐ»Ð¸Ð½Ð¸Ð²Ð°Ð½Ð¸Ðµ": "Ð—Ð°ÐºÐ»Ð¸Ð½Ð¸Ð²Ð°Ð½Ð¸Ðµ",
            "Ñ€ÐµÐ¼Ð¾Ð½Ñ‚": "Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚", "Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°": "ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹"
        }

        # ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ NER
        if "ner" not in self.nlp.pipe_names:
            self.ner = self.nlp.add_pipe("ner")
        else:
            self.ner = self.nlp.get_pipe("ner")

    def train_ner_model(self, train_data: List[tuple], output_dir: str = "iiot_ner_model", n_iter: int = 30):
        """ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ NER Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€Ð¾Ð¼"""
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ðº ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹
        for _, annotations in train_data:
            for ent in annotations.get("entities", []):
                self.ner.add_label(ent[2])

        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð²
        examples = []
        for text, annots in train_data:
            doc = self.nlp.make_doc(text)
            example = Example.from_dict(doc, annots)
            examples.append(example)

        # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð¾Ð¼ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°
        print(f"ðŸ”„ ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° {len(train_data)} Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°Ñ…...")
        optimizer = self.nlp.begin_training()

        for itn in range(n_iter):
            random.shuffle(examples)
            losses = {}
            batches = minibatch(examples, size=compounding(2.0, 16.0, 1.1))

            for batch in batches:
                self.nlp.update(batch, drop=0.3, losses=losses, sgd=optimizer)

            print(f"â³ Ð˜Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ñ {itn + 1}/{n_iter} | ÐŸÐ¾Ñ‚ÐµÑ€Ð¸: {losses['ner']:.3f}")

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        self.nlp.to_disk(output_dir)
        print(f"ðŸ’¾ ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² '{output_dir}'")

    def analyze_text(self, text: str) -> Dict[str, Any]:
        """ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸ÐµÐ¼ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð¸ Ð½ÐµÐ¸ÑÐ¿Ñ€Ð°Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹"""
        doc = self.nlp(text)

        # Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ NER
        ner_result = {
            "equipment": [],
            "equipment_id": [],
            "dates": [],
            "error_codes": [],
            "times": []
        }

        for ent in doc.ents:
            if ent.label_ == "EQUIPMENT":
                ner_result["equipment"].append(ent.text)
                # ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ID Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ
                id_part = ''.join(c for c in ent.text if c.isdigit())
                if id_part:
                    ner_result["equipment_id"].append(id_part)
            elif ent.label_ == "DATE":
                ner_result["dates"].append(ent.text)
            elif ent.label_ == "ERROR_CODE":
                ner_result["error_codes"].append(ent.text)
            elif ent.label_ == "TIME":
                ner_result["times"].append(ent.text)

        # ÐÐ½Ð°Ð»Ð¸Ð· Ð½ÐµÐ¸ÑÐ¿Ñ€Ð°Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹
        failure_result = {
            "equipment_type": self._get_equipment_type(doc),
            "components": self._get_components(doc),
            "symptoms": self._get_symptoms(doc),
            "urgency": self._detect_urgency(doc),
            "timestamp": self._get_timestamp(doc)
        }

        # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        return {
            "ner": ner_result,
            "failure_analysis": failure_result,
            "raw_text": text
        }

    def _get_equipment_type(self, doc) -> str:
        """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        for token in doc:
            if token.lemma_ in self.equipment_types:
                return self.equipment_types[token.lemma_]
        return "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾Ðµ Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ"

    def _get_components(self, doc) -> List[str]:
        """ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÐ¸ÑÐ¿Ñ€Ð°Ð²Ð½Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²"""
        found = []
        for token in doc:
            if token.lemma_ in self.components:
                found.append(self.components[token.lemma_])
        return found or ["ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½"]

    def _get_symptoms(self, doc) -> List[str]:
        """Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ð¾Ð²"""
        symptoms = []
        text_lower = doc.text.lower()

        for token in doc:
            if token.lemma_ in self.symptoms:
                symptoms.append(self.symptoms[token.lemma_])

        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°
        if "Ð½Ðµ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ" in text_lower or "Ð½Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ" in text_lower:
            symptoms.append("ÐÐµ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ")
        if "ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚" in text_lower:
            symptoms.append("Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚")

        return symptoms or ["Ð¡Ð¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹ Ð½Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ñ‹"]

    def _get_timestamp(self, doc) -> str:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð°Ñ‚Ñ‹/Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
        for ent in doc.ents:
            if ent.label_ == "DATE":
                return ent.text
        return datetime.now().strftime("%d.%m.%Y %H:%M")

    def _detect_urgency(self, doc) -> str:
        """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸"""
        text_lower = doc.text.lower()
        urgency_words = {
            "Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ": ["ÑÑ€Ð¾Ñ‡Ð½Ð¾", "Ð°Ð²Ð°Ñ€Ð¸Ñ", "Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ð»ÑÑ", "ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½", "ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ð¹"],
            "Ð½Ð¸Ð·ÐºÐ°Ñ": ["Ð½ÐµÐ·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½", "Ð¿Ð»Ð°Ð½Ð¾Ð²Ñ‹Ð¹", "Ð½Ðµ ÑÑ€Ð¾Ñ‡Ð½Ð¾"]
        }

        for level, words in urgency_words.items():
            if any(word in text_lower for word in words):
                return level.capitalize()
        return "Ð¡Ñ€ÐµÐ´Ð½ÑÑ"

    def pretty_print_analysis(self, analysis: Dict[str, Any]):
        """ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
        print(f"\nðŸ“‹ ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: '{analysis['raw_text']}'")
        print("=" * 60)

        print("\nðŸ” Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ñ‹Ðµ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚Ð¸:")
        for key, values in analysis["ner"].items():
            if values:
                print(f"- {key.upper()}: {', '.join(values)}")

        print("\nâš™ï¸ ÐÐ½Ð°Ð»Ð¸Ð· Ð½ÐµÐ¸ÑÐ¿Ñ€Ð°Ð²Ð½Ð¾ÑÑ‚ÐµÐ¹:")
        failure = analysis["failure_analysis"]
        print(f"- Ð¢Ð¸Ð¿ Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ: {failure['equipment_type']}")
        print(f"- ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹: {', '.join(failure['components'])}")
        print(f"- Ð¡Ð¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹: {', '.join(failure['symptoms'])}")
        print(f"- Ð¡Ñ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ: {failure['urgency']}")
        print(f"- Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð¼ÐµÑ‚ÐºÐ°: {failure['timestamp']}")
        print("=" * 60)


# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
TRAIN_DATA = [
    ("ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ ÑÑ‚Ð°Ð½ÐºÑƒ 5 Ð·Ð° Ð¸ÑŽÐ½ÑŒ 2023 Ð³Ð¾Ð´Ð°", {
        "entities": [(17, 24, "EQUIPMENT"), (28, 41, "DATE")]
    }),
    ("Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÑÑ‚Ð°Ð½ÐºÐ° 3 Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 2 Ð½ÐµÐ´ÐµÐ»Ð¸", {
        "entities": [(16, 23, "EQUIPMENT"), (27, 44, "DATE")]
    }),
    ("ÐžÑˆÐ¸Ð±ÐºÐ° E15 Ð½Ð° ÑÑ‚Ð°Ð½ÐºÐµ 5 Ð² 10:30", {
        "entities": [(7, 10, "ERROR_CODE"), (15, 22, "EQUIPMENT"), (26, 31, "TIME")]
    }),
]


def main():
    print("=" * 60)
    print("ðŸš€ ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð»Ñ IIoT.Istok")
    print("=" * 60)

    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÐµÐ¼
    if not Path("iiot_ner_model").exists():
        print("\nðŸ”Ž ÐžÐ±ÑƒÑ‡ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
        analyzer = IIoTAnalyzer()
        analyzer.train_ner_model(TRAIN_DATA)
    else:
        print("\nðŸ”Ž Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ")
        analyzer = IIoTAnalyzer("iiot_ner_model")

    # Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼
    while True:
        print("\nÐ’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð¸Ð»Ð¸ 'Ð²Ñ‹Ñ…Ð¾Ð´' Ð´Ð»Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ):")
        user_input = input("> ").strip()

        if user_input.lower() in ['Ð²Ñ‹Ñ…Ð¾Ð´', 'exit', 'quit']:
            break

        if user_input:
            analysis = analyzer.analyze_text(user_input)
            analyzer.pretty_print_analysis(analysis)


if __name__ == "__main__":
    main()